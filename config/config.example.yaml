# Obsidian MCP Server Configuration Example
# Copy this file to config.yaml and update with your values

# Server Configuration
server:
  host: "0.0.0.0"
  port: 8000
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Vault Configuration
vault:
  # Absolute path to your Obsidian vault
  path: "/path/to/your/obsidian/vault"

  # File extension for notes (default: md)
  note_extension: "md"

  # Maximum file size in MB
  max_file_size_mb: 10

  # Allowed file extensions for attachments
  allowed_extensions:
    - "md"
    - "pdf"
    - "png"
    - "jpg"
    - "jpeg"
    - "gif"
    - "svg"

# Authentication Configuration
auth:
  # Enable authentication (recommended for production)
  enabled: true

  # API keys (use environment variables in production: OBSIDIAN_API_KEYS)
  api_keys:
    - "your-secret-api-key-here"
    - "another-api-key"

  # Rate limiting
  rate_limit:
    enabled: true
    requests_per_minute: 60
    burst_size: 10

# CORS Configuration
cors:
  enabled: true
  allow_origins:
    - "http://localhost:3000"
    - "http://localhost:8080"
  allow_methods:
    - "GET"
    - "POST"
    - "PUT"
    - "DELETE"
  allow_headers:
    - "Authorization"
    - "Content-Type"

# Search Configuration
search:
  # Enable full-text search
  enabled: true

  # Maximum search results
  max_results: 100

  # Enable search result caching
  cache_enabled: true
  cache_ttl_seconds: 300

# Logging Configuration
logging:
  # Log file path (optional)
  file: "logs/mcp_obsidian.log"

  # Log format: json or text
  format: "json"

  # Include request/response logging
  log_requests: true

  # Include file operation audit trail
  audit_enabled: true

# RAG and Semantic Search Configuration
rag:
  # Enable RAG/semantic search features
  enabled: false

  # Embedding provider: ollama, openai, huggingface, cohere
  provider: "ollama"

  # Provider-specific configurations
  providers:
    # Ollama (local embeddings)
    ollama:
      base_url: "http://localhost:11434"
      model: "nomic-embed-text"  # or mxbai-embed-large
      timeout: 30

    # OpenAI embeddings
    openai:
      api_key: ""  # Set via environment variable: OBSIDIAN_RAG__PROVIDERS__OPENAI__API_KEY
      model: "text-embedding-3-small"
      dimensions: null  # Optional: specify dimensions

    # HuggingFace embeddings
    huggingface:
      model: "sentence-transformers/all-MiniLM-L6-v2"
      device: "cpu"  # cpu or cuda
      use_api: false  # Use HuggingFace API instead of local
      api_key: ""  # Required if use_api: true

    # Cohere embeddings
    cohere:
      api_key: ""  # Set via environment variable
      model: "embed-english-v3.0"

  # Vector store configuration
  vector_store: "chroma"  # chroma or faiss
  vector_db_path: "data/vector_db"

  # Document chunking strategy
  chunking:
    strategy: "smart"  # smart, fixed, or recursive
    chunk_size: 512  # Chunk size in characters
    chunk_overlap: 50  # Overlap between chunks
    split_on_headers: true  # Split on markdown headers

  # Search configuration
  search:
    hybrid_mode: true  # Combine semantic + keyword search
    semantic_weight: 0.7  # Weight for semantic results
    keyword_weight: 0.3  # Weight for keyword results
    top_k: 20  # Number of results to retrieve
    rerank: false  # Enable re-ranking (not implemented yet)

  # Performance settings
  cache_embeddings: true
  batch_size: 32
  index_on_startup: false  # Auto-index vault on server start
